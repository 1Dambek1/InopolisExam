{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "010c8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8986fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер X_train: (28824, 22)\n",
      "Размер X_test: (6854, 22)\n",
      "[[ 1.1600000e+02  4.8000000e+01  3.0000000e+01 ... -1.0000000e+00\n",
      "   1.4890217e+03  1.0000000e+00]\n",
      " [ 1.1600000e+02  5.7000000e+01  2.6000000e+01 ... -4.0000000e+00\n",
      "   1.4927789e+03  2.0000000e+00]\n",
      " [ 1.2300000e+02  4.0000000e+01  3.9000000e+01 ...  7.0000000e+00\n",
      "   1.5750912e+03  4.0000000e+00]\n",
      " ...\n",
      " [ 1.2200000e+02  5.2000000e+01  2.1000000e+01 ...  3.8000000e+01\n",
      "   1.4909344e+03  2.0000000e+00]\n",
      " [ 1.0600000e+02  5.1000000e+01  2.5000000e+01 ...  1.8000000e+01\n",
      "   1.5505931e+03  3.0000000e+00]\n",
      " [ 8.8000000e+01  3.5000000e+01  1.8000000e+01 ... -1.8000000e+01\n",
      "   1.5011953e+03  3.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "regular = pd.read_csv(\"datasets/regular_season_totals_2010_2024.csv\")\n",
    "playoff = pd.read_csv(\"datasets/play_off_totals_2010_2024.csv\")\n",
    "\n",
    "def get_data(regular, playoff):\n",
    "    totals = pd.concat([regular, playoff], ignore_index=True)\n",
    "    totals[\"GAME_DATE\"] = pd.to_datetime(totals[\"GAME_DATE\"])\n",
    "    totals = totals.sort_values(\"GAME_DATE\").reset_index(drop=True)\n",
    "\n",
    "    # победа дома\n",
    "    totals[\"is_home\"] = totals[\"MATCHUP\"].str.contains(\"vs.\")\n",
    "    totals[\"HOME_WIN\"] = ((totals[\"WL\"] == \"W\") & totals[\"is_home\"]).astype(int)\n",
    "\n",
    "    # Начальные ELO\n",
    "    teams = totals[\"TEAM_NAME\"].unique()\n",
    "    elo_ratings = {team: 1500 for team in teams}\n",
    "    last_game_date = {team: None for team in teams}\n",
    "\n",
    "    elo_list = []\n",
    "    rest_days_list = []\n",
    "\n",
    "\n",
    "    for _, row in totals.iterrows():\n",
    "        team = row[\"TEAM_NAME\"]\n",
    "        is_home = row[\"is_home\"]\n",
    "        date = row[\"GAME_DATE\"]\n",
    "\n",
    "        # ELO\n",
    "        elo = elo_ratings[team]\n",
    "        elo_list.append(elo)\n",
    "\n",
    "        # Rest\n",
    "        last_date = last_game_date[team]\n",
    "        rest_days = (date - last_date).days if last_date is not None else 7\n",
    "        rest_days_list.append(rest_days)\n",
    "\n",
    "        # updat ELO после игры\n",
    "        score = 1 if (row[\"WL\"] == \"W\" and is_home) or (row[\"WL\"] == \"L\" and not is_home) else 0\n",
    "        new_elo, _ = update_elo_single(elo_ratings[team], 1500, score)\n",
    "        elo_ratings[team] = new_elo\n",
    "        last_game_date[team] = date\n",
    "\n",
    "    totals[\"ELO\"] = elo_list\n",
    "    totals[\"REST_DAYS\"] = rest_days_list\n",
    "\n",
    "    # Фичи\n",
    "    features = [\n",
    "        \"PTS\", \"REB\", \"AST\", \"STL\", \"BLK\", \"TOV\",\n",
    "        \"FGM\", \"FGA\", \"FG_PCT\",\n",
    "        \"FG3M\", \"FG3A\", \"FG3_PCT\",\n",
    "        \"FTM\", \"FTA\", \"FT_PCT\",\n",
    "        \"OREB\", \"DREB\", \"PF\", \"PFD\", \"PLUS_MINUS\",\n",
    "        \"ELO\", \"REST_DAYS\"\n",
    "    ]\n",
    "\n",
    "    # Train / Test split по дате(чтобы не знал о будущих данных при shuffle )\n",
    "    split_date = pd.Timestamp(\"2022-01-01\")\n",
    "    train_dataset = totals[totals[\"GAME_DATE\"] < split_date]\n",
    "    test_dataset = totals[totals[\"GAME_DATE\"] >= split_date]\n",
    "\n",
    "    X_train = train_dataset[features].to_numpy().astype(np.float32)\n",
    "    y_train = train_dataset[\"HOME_WIN\"].to_numpy().astype(np.int64)\n",
    "\n",
    "    X_test = test_dataset[features].to_numpy().astype(np.float32)\n",
    "    y_test = test_dataset[\"HOME_WIN\"].to_numpy().astype(np.int64)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Функция обновления ELO для одного матча\n",
    "def update_elo_single(elo_a, elo_b, score_a, k=20):\n",
    "    expected_a = 1 / (1 + 10 ** ((elo_b - elo_a) / 400))\n",
    "    expected_b = 1 - expected_a\n",
    "    new_a = elo_a + k * (score_a - expected_a)\n",
    "    new_b = elo_b + k * ((1 - score_a) - expected_b)\n",
    "    return new_a, new_b\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data(regular, playoff)\n",
    "\n",
    "print(\"Размер X_train:\", X_train.shape)\n",
    "print(\"Размер X_test:\", X_test.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5e5ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "log_model = LogisticRegression()\n",
    "svm_model = SVC(kernel=\"rbf\")\n",
    "forest_model = RandomForestClassifier(max_depth=15)\n",
    "nn_model = nn.Sequential(\n",
    "    nn.Linear(22,64, bias=False),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(64,32, bias=False),\n",
    "    nn.BatchNorm1d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(32,2, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "163908f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.84      4928\n",
      "           1       0.58      0.74      0.65      1926\n",
      "\n",
      "    accuracy                           0.78      6854\n",
      "   macro avg       0.73      0.76      0.74      6854\n",
      "weighted avg       0.80      0.78      0.78      6854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)\n",
    "print(classification_report(y_test, xgb_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "13b80964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83      4928\n",
      "           1       0.57      0.80      0.67      1926\n",
      "\n",
      "    accuracy                           0.78      6854\n",
      "   macro avg       0.74      0.79      0.75      6854\n",
      "weighted avg       0.82      0.78      0.79      6854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_model.fit(X_train, y_train)\n",
    "print(classification_report(y_test, forest_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ad1ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84      4928\n",
      "           1       0.61      0.51      0.55      1926\n",
      "\n",
      "    accuracy                           0.77      6854\n",
      "   macro avg       0.71      0.69      0.70      6854\n",
      "weighted avg       0.76      0.77      0.76      6854\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mine\\code\\2025\\ml-ai\\nba_predictiction\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_model.fit(X_train, y_train)\n",
    "print(classification_report(y_test, log_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c72c323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84      4928\n",
      "           1       0.63      0.22      0.33      1926\n",
      "\n",
      "    accuracy                           0.74      6854\n",
      "   macro avg       0.69      0.58      0.58      6854\n",
      "weighted avg       0.72      0.74      0.70      6854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "print(classification_report(y_test, svm_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e5de435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 901/901 [00:02<00:00, 441.48it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 422.11it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 423.23it/s]\n",
      "100%|██████████| 901/901 [00:01<00:00, 473.80it/s]\n",
      "100%|██████████| 901/901 [00:01<00:00, 471.68it/s]\n",
      "100%|██████████| 901/901 [00:01<00:00, 462.11it/s]\n",
      "100%|██████████| 901/901 [00:01<00:00, 491.81it/s]\n",
      "100%|██████████| 901/901 [00:01<00:00, 476.44it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 378.78it/s]\n",
      "100%|██████████| 901/901 [00:01<00:00, 451.69it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 426.95it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 446.30it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 407.76it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 443.41it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 403.81it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 388.35it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 409.02it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 381.40it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 389.02it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 373.85it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 340.39it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 320.88it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 360.16it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 377.92it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 316.20it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 321.99it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 347.77it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 333.10it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 321.03it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 300.76it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 333.89it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 341.92it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 371.37it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 385.19it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 376.57it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 318.81it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 332.57it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 367.74it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 366.25it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 359.89it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 348.37it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 311.59it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 348.06it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 340.86it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 348.59it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 370.10it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 363.15it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 353.19it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 371.37it/s]\n",
      "100%|██████████| 901/901 [00:02<00:00, 356.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "class Dataset(torch_data.Dataset):\n",
    " def __init__(self, data_x, data_y):\n",
    "  super().__init__()\n",
    "  self.data_x = torch.tensor(data_x, dtype=torch.float32)\n",
    "  self.data_y = torch.tensor(data_y, dtype= torch.long)\n",
    "  self.length = len(data_y)\n",
    " def __getitem__(self, index):\n",
    "  return self.data_x[index], self.data_y[index]\n",
    " def __len__(self):\n",
    "  return self.length\n",
    "opt = optim.Adam(params=nn_model.parameters(), lr = 0.001, weight_decay=0.001)\n",
    "loss_func = nn.CrossEntropyLoss(weight=torch.tensor([0.28, 0.72]))\n",
    "d_train = Dataset(X_train, y_train)\n",
    "train_data = torch_data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
    "epochs = 50\n",
    "for _ in range(epochs):\n",
    " tqdm_data = tqdm(train_data)\n",
    " for x,y in tqdm_data:\n",
    "  predict = nn_model(x)\n",
    "  loss = loss_func(predict, y)\n",
    "  opt.zero_grad()\n",
    "  loss.backward()\n",
    "  opt.step()\n",
    " tqdm_data.set_description(f\"epochs : {_+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3cf5c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82      4928\n",
      "           1       0.56      0.97      0.71      1926\n",
      "\n",
      "    accuracy                           0.78      6854\n",
      "   macro avg       0.77      0.84      0.77      6854\n",
      "weighted avg       0.86      0.78      0.79      6854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_test = Dataset(X_test, y_test)\n",
    "test_data = torch_data.DataLoader(d_test, batch_size=len(d_test), shuffle=False)\n",
    "x,y = next(iter(test_data))\n",
    "predict = torch.argmax(nn_model(x), dim=1)\n",
    "print(classification_report(y_test, torch.argmax(nn_model(x), dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1036a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nn_model.state_dict(),\"model_params.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf06241",
   "metadata": {},
   "source": [
    "У нас дисбаланс классов матчей с проигрышем дома (0) больше — 4928,чем побед дома (1)  — 1926. Поэтому acc сам по себе мало что говорит, нужно смотреть precision и recall для каждого класса, особенно для редкого класса\n",
    "\n",
    "1. XGBoost\n",
    "\n",
    "Accuracy: 0.78 — неплохо\n",
    "\n",
    "Класс 0 (проигрыш дома): precision 0.88, recall 0.79  неплохо угадывает проигрыши\n",
    "\n",
    "Класс 1 (победа дома): precision 0.58, recall 0.74  модель находит большинство побед, но много ложных срабатываний\n",
    "F1 для победы 0.65 — средне.\n",
    "\n",
    "2. Random Forest\n",
    "\n",
    "Accuracy: 0.78 — как у XGBoost\n",
    "\n",
    "Класс 0: precision 0.91, recall 0.77  чуть лучше угадывает проигрыши, чем XGB\n",
    "\n",
    "Класс 1: precision 0.57, recall 0.80  recall выше, но precision чуть ниже  лучше ловит победы, но предсказывает их больше, чем на самом деле\n",
    "\n",
    "F1 для победы 0.67 — чуть лучше XGB\n",
    "\n",
    "3. Logistic Regression\n",
    "\n",
    "Accuracy: 0.77 — немного ниже\n",
    "\n",
    "Класс 0: precision 0.82, recall 0.87  хорошо угадывает проигрыши, но precision ниже  иногда «пропускает» проигрыши\n",
    "\n",
    "Класс 1: precision 0.61, recall 0.51  плохо ловит победы, много промахов\n",
    "\n",
    "F1 для победы 0.55 — хуже всех\n",
    "\n",
    "4. SVM\n",
    "\n",
    "Accuracy: 0.74 — самая низкая\n",
    "\n",
    "Класс 0: precision 0.76, recall 0.95  почти все проигрыши поймала, но за счёт того, что часто предсказывает проигрыш\n",
    "\n",
    "Класс 1: precision 0.63, recall 0.22  почти не находит победы дома  крайне плохой для редкого класса\n",
    "\n",
    "F1 для победы 0.33 — ужасно\n",
    "\n",
    "5. Neural Network (NN)\n",
    "\n",
    "Accuracy: 0.78 — на уровне XGB и Random Forest\n",
    "\n",
    "Класс 0: precision 0.99, recall 0.70 почти всегда, когда предсказывает проигрыш, оно верно, но часть проигрышей пропускает\n",
    "\n",
    "Класс 1: precision 0.56, recall 0.98 почти все реальные победы находит, но много ложных\n",
    "\n",
    "F1 для победы 0.71 — лучший результат среди всех\n",
    "\n",
    "Что видно по сути\n",
    "\n",
    "XGB и Random Forest примерно одинаковы по accuracy, но RF чуть лучше для побед дома  (0.67 vs 0.65)\n",
    "\n",
    "Logistic Regression и SVM плохо справляются с редким классом (победа дома)\n",
    "\n",
    "NN выделяется почти все победы дома находит (recall 0.98), и F1 для победы выше всех (0.71). Precision чуть ниже, но это нормально при дисбалансе\n",
    "\n",
    "Лучшая модель — Neural Network.\n",
    "\n",
    "Почему:\n",
    "\n",
    "Она лучше всего находит победы дома, что важнее при дисбалансе\n",
    "\n",
    "F1 для побед выше всех, значит баланс между precision и recall лучше, чем у других моделей.\n",
    "\n",
    "Accuracy примерно как у XGB/RF, но NN даёт лучшее качество предсказания редкого класса, а это ключевой момент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edecb7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-predictiction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
